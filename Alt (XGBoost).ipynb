{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d846834c-cec0-42d0-8ff6-1e253fd235d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "de436843-4d88-491e-9d10-ca1ae704489b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5e78b15d-67db-475f-a091-e7d0806cd477",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [11:42:20] WARNING: /usr/src/debug/python-xgboost/xgboost-2.1.2/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 96.15%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98    207338\n",
      "         1.0       0.71      0.32      0.44     10353\n",
      "\n",
      "    accuracy                           0.96    217691\n",
      "   macro avg       0.84      0.66      0.71    217691\n",
      "weighted avg       0.95      0.96      0.95    217691\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_df = data_df.drop(columns=['Age_x', 'Unnamed: 0.1', 'Unnamed: 0', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', 'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', 'CIF_MASK'])\n",
    "\n",
    "# Separate numerical and categorical columns in data.csv\n",
    "numerical_vars = data_df.select_dtypes(include=['number']).columns\n",
    "# to_scale_vars = numeric_vars.drop(columns = [''])\n",
    "categorical_vars = data_df.select_dtypes(exclude=['number']).columns\n",
    "data_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# data_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "\n",
    "# def preprocess_data(df):\n",
    "#     # Separate categorical and numerical columns\n",
    "#     categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "#     numerical_cols = df.select_dtypes(exclude=['object']).columns\n",
    "    \n",
    "#     # Preprocess with OneHotEncoder and StandardScaler\n",
    "#     preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', Pipeline([\n",
    "#             ('imputer', SimpleImputer(strategy='constant', fill_value=-9999999999999999999999)),\n",
    "#             ('scaler', StandardScaler())\n",
    "#         ]), numerical_cols),\n",
    "        \n",
    "#         ('cat', Pipeline([\n",
    "#             ('imputer', SimpleImputer(strategy='constant', fill_value='None')),\n",
    "#             # ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#             ('encoder', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "#         ]), categorical_cols)\n",
    "#         ])\n",
    "    \n",
    "#     processed_data = preprocessor.fit_transform(df)\n",
    "#     return processed_data, preprocessor\n",
    "\n",
    "\n",
    "\n",
    "# Split features and target\n",
    "X = data_df.drop(columns=['IS_BANCAS'])\n",
    "y = data_df['IS_BANCAS']\n",
    "\n",
    "\n",
    "# Handle categorical variables\n",
    "# For simplicity, using one-hot encoding, though other methods (target encoding) could be considered\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the XGBoost classifier\n",
    "xgb_clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss', missing=np.nan)\n",
    "\n",
    "# Fit the model\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "y_pred = xgb_clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "accuracy = round(accuracy, 4)\n",
    "print(\"Model Accuracy:\", str(accuracy*100) + \"%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Predict on a new observation\n",
    "# Replace with a new observation, ensuring it matches the training feature format\n",
    "new_observation = X_test.iloc[0]  # Example of using an observation from test set\n",
    "# new_pred = xgb_clf.predict(np.array([new_observation]))\n",
    "# print(\"Prediction for new observation (IS_BANCAS):\", new_pred[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
