<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335354-1f9a-404c-aa19-ad04186705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d523ca8-4e7a-44d5-99da-4b957ae849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing functions\n",
    "def bin_age_groups(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Bin the 'Age_y' column into defined age groups.\n",
    "    \"\"\"\n",
    "    age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "    labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', \n",
    "              '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "    \n",
    "    train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    Preprocess train and test datasets by aligning columns, binning age groups,\n",
    "    applying quantile-based labeling, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "\n",
    "    # Retain only common columns\n",
    "    common_columns = list(set(train.columns) & set(test.columns))\n",
    "    train = train[common_columns]\n",
    "    test = test[common_columns]\n",
    "\n",
    "    # Drop specified columns\n",
    "    cols_to_drop = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', \n",
    "                    'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                    'CIF_MASK', 'IS_TM', 'Unnamed: 0', \n",
    "                    'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "    train = train.drop(columns=[col for col in cols_to_drop if col in train.columns], errors='ignore')\n",
    "    test = test.drop(columns=[col for col in cols_to_drop if col in test.columns], errors='ignore')\n",
    "\n",
    "    # Bin age groups\n",
    "    train, test = bin_age_groups(train, test)\n",
    "    return train, test\n",
    "\n",
    "# Model functions\n",
    "def save_model(train, model_path):\n",
    "    \"\"\"\n",
    "    Save the trained model (normalized data and parameters) to a pickle file.\n",
    "    \"\"\"\n",
    "    X_train = train.drop(columns=[\"IS_BANCAS\"])\n",
    "    y_train = train[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    X_train = pd.get_dummies(X_train, drop_first=True)\n",
    "    X_train = X_train.astype(float).to_numpy()\n",
    "\n",
    "    mean = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train, axis=0)\n",
    "    std[std == 0] = 1  # Avoid division by zero\n",
    "\n",
    "    X_train_normalized = (X_train - mean) / std\n",
    "\n",
    "    model = {\n",
    "        \"X_train\": X_train_normalized,\n",
    "        \"y_train\": y_train,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_most_similar(X_test, X_train, y_train, top_k=20):\n",
    "    \"\"\"\n",
    "    Compute the dot product between X_test and X_train in chunks, and find the top-k most similar observations.\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for i in range(X_test.shape[0]):\n",
    "        # Compute similarity row by row to avoid memory issues\n",
    "        similarities = np.dot(X_test[i], X_train.T)\n",
    "        top_k_indices = np.argsort(-similarities)[:top_k]\n",
    "        top_k_labels = y_train[top_k_indices]\n",
    "        predicted_label = round(np.mean(top_k_labels))\n",
    "        predictions.append(predicted_label)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "def evaluate_model(test, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Evaluate the model using the dot product similarity in chunks.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"])\n",
    "    y_test = test[\"IS_BANCAS\"]\n",
    "\n",
    "    X_test = pd.get_dummies(X_test, drop_first=True)\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    X_test = X_test.reindex(columns=X_train_df.columns, fill_value=0)\n",
    "\n",
    "    X_test = X_test.to_numpy().astype(float)\n",
    "    X_test = (X_test - mean) / std\n",
    "\n",
    "    # Predict in chunks to avoid memory issues\n",
    "    predicted_bancas = find_most_similar(X_test, X_train, y_train, top_k)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predicted_bancas)\n",
    "    auc = roc_auc_score(y_test, predicted_bancas)\n",
    "    gini_index = 2 * auc - 1\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted_bancas)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, gini_index\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    train_path = \"data.csv\"\n",
    "    test_path = \"data-val.parquet\"\n",
    "    model_path = \"results/collaborative_search_dot_product_model.pkl\"\n",
    "\n",
    "    print(\"Preprocessing data...\")\n",
    "    train, test = preprocess_data(train_path, test_path)\n",
    "\n",
    "    print(\"Training and saving the model...\")\n",
    "    save_model(train, model_path)\n",
    "\n",
    "    print(\"Evaluating the model...\")\n",
    "    accuracy, gini_index = evaluate_model(test, model_path, top_k=20)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Gini Index: {gini_index:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74e7252-9a86-4476-9ea3-193393c0f3db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
||||||| 623aedd
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335354-1f9a-404c-aa19-ad04186705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d523ca8-4e7a-44d5-99da-4b957ae849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling function\n",
    "def labelling(df, col, num_bins):\n",
    "    \"\"\"\n",
    "    Apply quantile-based binning to a column in the DataFrame.\n",
    "    \"\"\"\n",
    "    df[col] = pd.qcut(df[col], q=num_bins, labels=False, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "# Binning function for age groups\n",
    "def bin_age_groups(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Bin the 'Age_y' column into defined age groups.\n",
    "    \"\"\"\n",
    "    age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "    labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', \n",
    "              '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "\n",
    "    train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    Preprocess train and test datasets by aligning columns, binning age groups,\n",
    "    applying quantile-based labelling, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "\n",
    "    # Retain only common columns\n",
    "    common_columns = list(set(train.columns) & set(test.columns))\n",
    "    train = train[common_columns]\n",
    "    test = test[common_columns]\n",
    "\n",
    "    # Drop specified columns\n",
    "    cols_to_drop = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', \n",
    "                    'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                    'CIF_MASK', 'IS_TM', 'Unnamed: 0', \n",
    "                    'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "    train = train.drop(columns=[col for col in cols_to_drop if col in train.columns], errors='ignore')\n",
    "    test = test.drop(columns=[col for col in cols_to_drop if col in test.columns], errors='ignore')\n",
    "\n",
    "    # Bin age groups\n",
    "    train, test = bin_age_groups(train, test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# Model functions (same as previous)\n",
    "def save_model(train, model_path):\n",
    "    \"\"\"\n",
    "    Save the trained model (normalized data and parameters) to a pickle file.\n",
    "    \"\"\"\n",
    "    X_train = train.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_train = train[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "\n",
    "    X_train_normalized = (X_train - mean) / std\n",
    "\n",
    "    model = {\n",
    "        \"X_train\": X_train_normalized,\n",
    "        \"y_train\": y_train,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def predict_new_observation(new_observation, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Load the model and predict the expected IS_BANCAS value for a new observation.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    new_observation = (new_observation - mean) / std\n",
    "    similarity = np.dot(X_train, new_observation)\n",
    "    top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "    top_k_bancas = y_train[top_k_indices]\n",
    "    predicted_bancas = round(top_k_bancas.mean())\n",
    "    return predicted_bancas\n",
    "\n",
    "def evaluate_model(test, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Evaluate the model using the test dataset.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_test = test[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    X_test = (X_test - mean) / std\n",
    "    similarity_matrix = np.dot(X_test, X_train.T)\n",
    "\n",
    "    predicted_bancas = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        top_k_indices = np.argsort(-similarity_matrix[i])[:top_k]\n",
    "        top_k_bancas = y_train[top_k_indices]\n",
    "        predicted_bancas.append(round(top_k_bancas.mean()))\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predicted_bancas)\n",
    "\n",
    "    # Gini index\n",
    "    auc = roc_auc_score(y_test, predicted_bancas)\n",
    "    gini_index = 2 * auc - 1\n",
    "\n",
    "    # ROC-AUC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted_bancas)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, gini_index\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    train_path = \"data.csv\"\n",
    "    test_path = \"data-val.parquet\"\n",
    "    model_path = \"/results/collaborative_search_dot_product_model.pkl\"\n",
    "\n",
    "    # Step 1: Preprocess data\n",
    "    print(\"Preprocessing data...\")\n",
    "    train, test = preprocess_data(train_path, test_path)\n",
    "\n",
    "    # Step 2: Train and save the model\n",
    "    print(\"Training and saving the model...\")\n",
    "    save_model(train, model_path)\n",
    "\n",
    "    # Step 3: Evaluate the model\n",
    "    print(\"Evaluating the model...\")\n",
    "    accuracy, gini_index = evaluate_model(test, model_path, top_k=20)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Gini Index: {gini_index:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 70dd9a967763945df50a79ddf407886e41adeb80
||||||| 623aedd
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335354-1f9a-404c-aa19-ad04186705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d523ca8-4e7a-44d5-99da-4b957ae849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling function\n",
    "def labelling(df, col, num_bins):\n",
    "    \"\"\"\n",
    "    Apply quantile-based binning to a column in the DataFrame.\n",
    "    \"\"\"\n",
    "    df[col] = pd.qcut(df[col], q=num_bins, labels=False, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "# Binning function for age groups\n",
    "def bin_age_groups(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Bin the 'Age_y' column into defined age groups.\n",
    "    \"\"\"\n",
    "    age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "    labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', \n",
    "              '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "\n",
    "    train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    Preprocess train and test datasets by aligning columns, binning age groups,\n",
    "    applying quantile-based labelling, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "\n",
    "    # Retain only common columns\n",
    "    common_columns = list(set(train.columns) & set(test.columns))\n",
    "    train = train[common_columns]\n",
    "    test = test[common_columns]\n",
    "\n",
    "    # Drop specified columns\n",
    "    cols_to_drop = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', \n",
    "                    'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                    'CIF_MASK', 'IS_TM', 'Unnamed: 0', \n",
    "                    'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "    train = train.drop(columns=[col for col in cols_to_drop if col in train.columns], errors='ignore')\n",
    "    test = test.drop(columns=[col for col in cols_to_drop if col in test.columns], errors='ignore')\n",
    "\n",
    "    # Bin age groups\n",
    "    train, test = bin_age_groups(train, test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# Model functions (same as previous)\n",
    "def save_model(train, model_path):\n",
    "    \"\"\"\n",
    "    Save the trained model (normalized data and parameters) to a pickle file.\n",
    "    \"\"\"\n",
    "    X_train = train.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_train = train[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "\n",
    "    X_train_normalized = (X_train - mean) / std\n",
    "\n",
    "    model = {\n",
    "        \"X_train\": X_train_normalized,\n",
    "        \"y_train\": y_train,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def predict_new_observation(new_observation, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Load the model and predict the expected IS_BANCAS value for a new observation.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    new_observation = (new_observation - mean) / std\n",
    "    similarity = np.dot(X_train, new_observation)\n",
    "    top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "    top_k_bancas = y_train[top_k_indices]\n",
    "    predicted_bancas = round(top_k_bancas.mean())\n",
    "    return predicted_bancas\n",
    "\n",
    "def evaluate_model(test, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Evaluate the model using the test dataset.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_test = test[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    X_test = (X_test - mean) / std\n",
    "    similarity_matrix = np.dot(X_test, X_train.T)\n",
    "\n",
    "    predicted_bancas = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        top_k_indices = np.argsort(-similarity_matrix[i])[:top_k]\n",
    "        top_k_bancas = y_train[top_k_indices]\n",
    "        predicted_bancas.append(round(top_k_bancas.mean()))\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predicted_bancas)\n",
    "\n",
    "    # Gini index\n",
    "    auc = roc_auc_score(y_test, predicted_bancas)\n",
    "    gini_index = 2 * auc - 1\n",
    "\n",
    "    # ROC-AUC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted_bancas)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, gini_index\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    train_path = \"data.csv\"\n",
    "    test_path = \"data-val.parquet\"\n",
    "    model_path = \"/results/collaborative_search_dot_product_model.pkl\"\n",
    "\n",
    "    # Step 1: Preprocess data\n",
    "    print(\"Preprocessing data...\")\n",
    "    train, test = preprocess_data(train_path, test_path)\n",
    "\n",
    "    # Step 2: Train and save the model\n",
    "    print(\"Training and saving the model...\")\n",
    "    save_model(train, model_path)\n",
    "\n",
    "    # Step 3: Evaluate the model\n",
    "    print(\"Evaluating the model...\")\n",
    "    accuracy, gini_index = evaluate_model(test, model_path, top_k=20)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Gini Index: {gini_index:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 70dd9a967763945df50a79ddf407886e41adeb80
||||||| 623aedd
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335354-1f9a-404c-aa19-ad04186705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d523ca8-4e7a-44d5-99da-4b957ae849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling function\n",
    "def labelling(df, col, num_bins):\n",
    "    \"\"\"\n",
    "    Apply quantile-based binning to a column in the DataFrame.\n",
    "    \"\"\"\n",
    "    df[col] = pd.qcut(df[col], q=num_bins, labels=False, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "# Binning function for age groups\n",
    "def bin_age_groups(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Bin the 'Age_y' column into defined age groups.\n",
    "    \"\"\"\n",
    "    age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "    labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', \n",
    "              '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "\n",
    "    train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    Preprocess train and test datasets by aligning columns, binning age groups,\n",
    "    applying quantile-based labelling, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "\n",
    "    # Retain only common columns\n",
    "    common_columns = list(set(train.columns) & set(test.columns))\n",
    "    train = train[common_columns]\n",
    "    test = test[common_columns]\n",
    "\n",
    "    # Drop specified columns\n",
    "    cols_to_drop = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', \n",
    "                    'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                    'CIF_MASK', 'IS_TM', 'Unnamed: 0', \n",
    "                    'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "    train = train.drop(columns=[col for col in cols_to_drop if col in train.columns], errors='ignore')\n",
    "    test = test.drop(columns=[col for col in cols_to_drop if col in test.columns], errors='ignore')\n",
    "\n",
    "    # Bin age groups\n",
    "    train, test = bin_age_groups(train, test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# Model functions (same as previous)\n",
    "def save_model(train, model_path):\n",
    "    \"\"\"\n",
    "    Save the trained model (normalized data and parameters) to a pickle file.\n",
    "    \"\"\"\n",
    "    X_train = train.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_train = train[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "\n",
    "    X_train_normalized = (X_train - mean) / std\n",
    "\n",
    "    model = {\n",
    "        \"X_train\": X_train_normalized,\n",
    "        \"y_train\": y_train,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def predict_new_observation(new_observation, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Load the model and predict the expected IS_BANCAS value for a new observation.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    new_observation = (new_observation - mean) / std\n",
    "    similarity = np.dot(X_train, new_observation)\n",
    "    top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "    top_k_bancas = y_train[top_k_indices]\n",
    "    predicted_bancas = round(top_k_bancas.mean())\n",
    "    return predicted_bancas\n",
    "\n",
    "def evaluate_model(test, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Evaluate the model using the test dataset.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_test = test[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    X_test = (X_test - mean) / std\n",
    "    similarity_matrix = np.dot(X_test, X_train.T)\n",
    "\n",
    "    predicted_bancas = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        top_k_indices = np.argsort(-similarity_matrix[i])[:top_k]\n",
    "        top_k_bancas = y_train[top_k_indices]\n",
    "        predicted_bancas.append(round(top_k_bancas.mean()))\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predicted_bancas)\n",
    "\n",
    "    # Gini index\n",
    "    auc = roc_auc_score(y_test, predicted_bancas)\n",
    "    gini_index = 2 * auc - 1\n",
    "\n",
    "    # ROC-AUC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted_bancas)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, gini_index\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    train_path = \"data.csv\"\n",
    "    test_path = \"data-val.parquet\"\n",
    "    model_path = \"/results/collaborative_search_dot_product_model.pkl\"\n",
    "\n",
    "    # Step 1: Preprocess data\n",
    "    print(\"Preprocessing data...\")\n",
    "    train, test = preprocess_data(train_path, test_path)\n",
    "\n",
    "    # Step 2: Train and save the model\n",
    "    print(\"Training and saving the model...\")\n",
    "    save_model(train, model_path)\n",
    "\n",
    "    # Step 3: Evaluate the model\n",
    "    print(\"Evaluating the model...\")\n",
    "    accuracy, gini_index = evaluate_model(test, model_path, top_k=20)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Gini Index: {gini_index:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> 70dd9a967763945df50a79ddf407886e41adeb80
||||||| 623aedd
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8335354-1f9a-404c-aa19-ad04186705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d523ca8-4e7a-44d5-99da-4b957ae849a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling function\n",
    "def labelling(df, col, num_bins):\n",
    "    \"\"\"\n",
    "    Apply quantile-based binning to a column in the DataFrame.\n",
    "    \"\"\"\n",
    "    df[col] = pd.qcut(df[col], q=num_bins, labels=False, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "# Binning function for age groups\n",
    "def bin_age_groups(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Bin the 'Age_y' column into defined age groups.\n",
    "    \"\"\"\n",
    "    age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "    labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', \n",
    "              '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "\n",
    "    train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    Preprocess train and test datasets by aligning columns, binning age groups,\n",
    "    applying quantile-based labelling, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    # Load datasets\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "\n",
    "    # Retain only common columns\n",
    "    common_columns = list(set(train.columns) & set(test.columns))\n",
    "    train = train[common_columns]\n",
    "    test = test[common_columns]\n",
    "\n",
    "    # Drop specified columns\n",
    "    cols_to_drop = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', \n",
    "                    'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                    'CIF_MASK', 'IS_TM', 'Unnamed: 0', \n",
    "                    'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "    train = train.drop(columns=[col for col in cols_to_drop if col in train.columns], errors='ignore')\n",
    "    test = test.drop(columns=[col for col in cols_to_drop if col in test.columns], errors='ignore')\n",
    "\n",
    "    # Bin age groups\n",
    "    train, test = bin_age_groups(train, test)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "# Model functions (same as previous)\n",
    "def save_model(train, model_path):\n",
    "    \"\"\"\n",
    "    Save the trained model (normalized data and parameters) to a pickle file.\n",
    "    \"\"\"\n",
    "    X_train = train.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_train = train[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "\n",
    "    X_train_normalized = (X_train - mean) / std\n",
    "\n",
    "    model = {\n",
    "        \"X_train\": X_train_normalized,\n",
    "        \"y_train\": y_train,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def predict_new_observation(new_observation, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Load the model and predict the expected IS_BANCAS value for a new observation.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    new_observation = (new_observation - mean) / std\n",
    "    similarity = np.dot(X_train, new_observation)\n",
    "    top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "    top_k_bancas = y_train[top_k_indices]\n",
    "    predicted_bancas = round(top_k_bancas.mean())\n",
    "    return predicted_bancas\n",
    "\n",
    "def evaluate_model(test, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Evaluate the model using the test dataset.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "    y_test = test[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    X_test = (X_test - mean) / std\n",
    "    similarity_matrix = np.dot(X_test, X_train.T)\n",
    "\n",
    "    predicted_bancas = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        top_k_indices = np.argsort(-similarity_matrix[i])[:top_k]\n",
    "        top_k_bancas = y_train[top_k_indices]\n",
    "        predicted_bancas.append(round(top_k_bancas.mean()))\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_score(y_test, predicted_bancas)\n",
    "\n",
    "    # Gini index\n",
    "    auc = roc_auc_score(y_test, predicted_bancas)\n",
    "    gini_index = 2 * auc - 1\n",
    "\n",
    "    # ROC-AUC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, predicted_bancas)\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='blue', label=f'ROC curve (AUC = {auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "    return accuracy, gini_index\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # File paths\n",
    "    train_path = \"data.csv\"\n",
    "    test_path = \"data-val.parquet\"\n",
    "    model_path = \"/results/collaborative_search_dot_product_model.pkl\"\n",
    "\n",
    "    # Step 1: Preprocess data\n",
    "    print(\"Preprocessing data...\")\n",
    "    train, test = preprocess_data(train_path, test_path)\n",
    "\n",
    "    # Step 2: Train and save the model\n",
    "    print(\"Training and saving the model...\")\n",
    "    save_model(train, model_path)\n",
    "\n",
    "    # Step 3: Evaluate the model\n",
    "    print(\"Evaluating the model...\")\n",
    "    accuracy, gini_index = evaluate_model(test, model_path, top_k=20)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(f\"Gini Index: {gini_index:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
>>>>>>> origin/main
