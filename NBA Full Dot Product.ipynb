{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8335354-1f9a-404c-aa19-ad04186705e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d523ca8-4e7a-44d5-99da-4b957ae849a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing data...\n",
      "Numeric columns aligned: ['CBALQ_3m', 'AVG_SL_SP_BOSUNG', 'NO_TREN_CO_6m', 'SUM_CBALQ_LH', 'BHNT_flag', 'MEDIAN_GR_SUM_AMT', 'BHNT_after21', 'Sum_PPC', 'MEDIAN_GR_THGCO', 'BHSK_remain', 'IS_BANCAS', 'AVG_GR_CBALQ', 'CBALQ_6m', 'AVG_CBALQ_6m', 'BHNT_remain', 'AVG_GR_THGCO', 'IS_TM.1', 'Age_y', 'THGCO_3m', 'CNT_TGCCKH', 'THGNO_6m', 'IS_TA', 'TONGTHUNHAPHANGTHANG', 'Snapshot', 'BHSK_flag', 'THGCO_6m', 'MEDIAN_GR_CBALQ', 'AVG_CBALQ_TGCCKH', 'THGNO_3m', 'AVG_AMT_3M', 'NO_TREN_CO_3m', 'AVG_CBALQ_3m', 'BHSK_after21', 'Payroll_Flag', 'AVG_GR_THGNO', 'MEDIAN_GR_THGNO']\n",
      "Training and saving the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeus\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\_methods.py:173: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n",
      "C:\\Users\\Zeus\\AppData\\Local\\Temp\\ipykernel_1848\\4242241194.py:68: RuntimeWarning: invalid value encountered in subtract\n",
      "  X_train_normalized = (X_train - mean) / (std +1e-8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to results/collaborative_search_dot_product_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Labelling function\n",
    "def labelling(df, col, num_bins):\n",
    "    \"\"\"\n",
    "    Apply quantile-based binning to a column in the DataFrame.\n",
    "    \"\"\"\n",
    "    df[col] = pd.qcut(df[col], q=num_bins, labels=False, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "# Binning function for age groups\n",
    "def bin_age_groups(train_df, test_df):\n",
    "    \"\"\"\n",
    "    Bin the 'Age_y' column into defined age groups.\n",
    "    \"\"\"\n",
    "    age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "    labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', \n",
    "              '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "\n",
    "    train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "    return train_df, test_df\n",
    "\n",
    "def preprocess_data(train_path, test_path):\n",
    "    \"\"\"\n",
    "    Preprocess train and test datasets by aligning numeric columns, \n",
    "    binning age groups, and dropping unnecessary columns.\n",
    "    \"\"\"\n",
    "    train = pd.read_csv(train_path)\n",
    "    test = pd.read_parquet(test_path)\n",
    "\n",
    "    # Drop specified columns\n",
    "    cols_to_drop = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', \n",
    "                    'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                    'CIF_MASK', 'IS_TM', 'Unnamed: 0', \n",
    "                    'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "    train = train.drop(columns=[col for col in cols_to_drop if col in train.columns], errors='ignore')\n",
    "    test = test.drop(columns=[col for col in cols_to_drop if col in test.columns], errors='ignore')\n",
    "\n",
    "    # Bin age groups\n",
    "    train, test = bin_age_groups(train, test)\n",
    "\n",
    "    # Align numeric columns\n",
    "    numeric_cols = train.select_dtypes(include=[np.number]).columns.intersection(\n",
    "        test.select_dtypes(include=[np.number]).columns\n",
    "    )\n",
    "    train = train[numeric_cols]\n",
    "    test = test[numeric_cols]\n",
    "\n",
    "    print(f\"Numeric columns aligned: {numeric_cols.tolist()}\")\n",
    "    return train, test\n",
    "\n",
    "\n",
    "\n",
    "# Model functions (same as previous)\n",
    "def save_model(train, model_path):\n",
    "    \"\"\"\n",
    "    Save the trained model (normalized data and parameters) to a pickle file.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns\n",
    "    numeric_cols = train.select_dtypes(include=[np.number]).columns\n",
    "    X_train = train[numeric_cols].drop(columns=[\"IS_BANCAS\"], errors='ignore').to_numpy()\n",
    "    y_train = train[\"IS_BANCAS\"].to_numpy()\n",
    "\n",
    "    # Calculate mean and standard deviation\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "\n",
    "    # Normalize X_train\n",
    "    X_train_normalized = (X_train - mean) / (std +1e-8)\n",
    "\n",
    "    # Save the model\n",
    "    model = {\n",
    "        \"X_train\": X_train_normalized,\n",
    "        \"y_train\": y_train,\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "def predict_new_observation(new_observation, model_path, top_k=20):\n",
    "    \"\"\"\n",
    "    Load the model and predict the expected IS_BANCAS value for a new observation.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    new_observation = (new_observation - mean) / std\n",
    "    similarity = np.dot(X_train, new_observation)\n",
    "    top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "    top_k_bancas = y_train[top_k_indices]\n",
    "    predicted_bancas = round(top_k_bancas.mean())\n",
    "    return predicted_bancas\n",
    "\n",
    "def predict_first_n_observations(test, model_path, n=10, top_k=20):\n",
    "    \"\"\"\n",
    "    Predict the \"IS_BANCAS\" value for the first N observations in the test dataset\n",
    "    and print the actual and predicted values.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    # Get the first N observations and their actual IS_BANCAS values\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"]).iloc[:n].to_numpy()\n",
    "    actual_values = test[\"IS_BANCAS\"].iloc[:n].to_numpy()\n",
    "\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"mean shape: {mean.shape}\")\n",
    "    print(f\"std shape: {std.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "    # Normalize test data\n",
    "    X_test = (X_test - mean) / (std + 1e-8)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        # Calculate similarity and predict IS_BANCAS\n",
    "        similarity = np.dot(X_train, X_test[i])\n",
    "        top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "        top_k_bancas = y_train[top_k_indices]\n",
    "        predicted_bancas = top_k_bancas.mean()\n",
    "        predictions.append(predicted_bancas)\n",
    "\n",
    "        # Print the predicted and actual IS_BANCAS values\n",
    "        # print(f\"Observation {i + 1}: Predicted IS_BANCAS = {predicted_bancas}, Actual IS_BANCAS = {actual_values[i]}\")\n",
    "\n",
    "    # Add the predictions as a new column in the DataFrame\n",
    "    test[\"predicted_IS_BANCAS\"] = np.nan\n",
    "    test[\"predicted_IS_BANCAS\"].iloc[:n] = predictions\n",
    "\n",
    "    # Print the Age_y, actual, and predicted values for the first N rows\n",
    "    for i in range(n):\n",
    "        print(f\"Row {i}: Age_y = {test.iloc[i]['Age_y']}, Actual IS_BANCAS = {test.iloc[i]['IS_BANCAS']}, Predicted IS_BANCAS = {test.iloc[i]['predicted_IS_BANCAS']}\")\n",
    "\n",
    "    return predictions\n",
    "\n",
    "    \n",
    "def predict_all_observations(test, model_path, top_k=20, print_n=10):\n",
    "    \"\"\"\n",
    "    Predict the \"IS_BANCAS\" value for all observations in the test dataset\n",
    "    and add the predictions as a new column. Print out predictions for the first `print_n` rows.\n",
    "    \"\"\"\n",
    "    with open(model_path, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "\n",
    "    X_train = model[\"X_train\"]\n",
    "    y_train = model[\"y_train\"]\n",
    "    mean = model[\"mean\"]\n",
    "    std = model[\"std\"]\n",
    "\n",
    "    # Get all observations from the test set (excluding IS_BANCAS column)\n",
    "    X_test = test.drop(columns=[\"IS_BANCAS\"]).to_numpy()\n",
    "\n",
    "    # Normalize test data\n",
    "    X_test = (X_test - mean) / (std + 1e-8)\n",
    "\n",
    "    predictions = []\n",
    "    for i in range(X_test.shape[0]):\n",
    "        # Calculate similarity and predict IS_BANCAS\n",
    "        similarity = np.dot(X_train, X_test[i])\n",
    "        top_k_indices = np.argsort(-similarity)[:top_k]\n",
    "        top_k_bancas = y_train[top_k_indices]\n",
    "        predicted_bancas = top_k_bancas.mean()\n",
    "        predictions.append(predicted_bancas)\n",
    "\n",
    "    # Add the predictions to the test DataFrame\n",
    "    test[\"predicted_IS_BANCAS\"] = predictions\n",
    "\n",
    "    # Optionally, print out the first few predictions for inspection\n",
    "    print(f\"Showing the first {min(print_n, len(test))} predictions:\")\n",
    "    print(test[['IS_BANCAS', 'predicted_IS_BANCAS']].head(print_n))\n",
    "\n",
    "    return test\n",
    "\n",
    "\n",
    "# File paths\n",
    "train_path = \"data.csv\"\n",
    "test_path = \"data-val.parquet\"\n",
    "model_path = \"results/collaborative_search_dot_product_model.pkl\"\n",
    "\n",
    "# Step 1: Preprocess data\n",
    "print(\"Preprocessing data...\")\n",
    "train, test = preprocess_data(train_path, test_path)\n",
    "\n",
    "# Step 2: Train and save the model\n",
    "print(\"Training and saving the model...\")\n",
    "save_model(train, model_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d53dd30b-05bd-40a5-bfc9-e3b9e434481d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting all observations in the test dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zeus\\AppData\\Local\\Temp\\ipykernel_1848\\4242241194.py:165: RuntimeWarning: invalid value encountered in subtract\n",
      "  X_test = (X_test - mean) / (std + 1e-8)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 3: Predict all observations in the test dataset and show the first 10 predictions\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicting all observations in the test dataset...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m predicted_test_data \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_all_observations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m predict_first_n_observations(test, model_path, n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, top_k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n",
      "Cell \u001b[1;32mIn[5], line 171\u001b[0m, in \u001b[0;36mpredict_all_observations\u001b[1;34m(test, model_path, top_k, print_n)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X_test\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m    169\u001b[0m     \u001b[38;5;66;03m# Calculate similarity and predict IS_BANCAS\u001b[39;00m\n\u001b[0;32m    170\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_train, X_test[i])\n\u001b[1;32m--> 171\u001b[0m     top_k_indices \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43msimilarity\u001b[49m\u001b[43m)\u001b[49m[:top_k]\n\u001b[0;32m    172\u001b[0m     top_k_bancas \u001b[38;5;241m=\u001b[39m y_train[top_k_indices]\n\u001b[0;32m    173\u001b[0m     predicted_bancas \u001b[38;5;241m=\u001b[39m top_k_bancas\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[1;34m(a, axis, kind, order)\u001b[0m\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[0;32m   1029\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \n\u001b[0;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 3: Predict all observations in the test dataset and show the first 10 predictions\n",
    "print(\"Predicting all observations in the test dataset...\")\n",
    "predicted_test_data = predict_all_observations(test, model_path, top_k=20, print_n=10)\n",
    "predict_first_n_observations(test, model_path, n=1000, top_k=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a457d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
