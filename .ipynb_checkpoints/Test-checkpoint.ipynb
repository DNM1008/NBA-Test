{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f42b40-d227-4c0d-8883-8a95add5f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "train_df = pd.read_csv('data.csv')\n",
    "test_df = pd.read_parquet('data-val.parquet')\n",
    "\n",
    "# Ensure the datasets have the same columns\n",
    "common_columns = train_df.columns.intersection(test_df.columns)\n",
    "removed_columns = set(train_df.columns).symmetric_difference(test_df.columns)\n",
    "train_df_filtered = train_df[common_columns]\n",
    "test_df_filtered = test_df[common_columns]\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "drop_columns = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', 'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                'CIF_MASK', 'IS_TM', 'Unnamed: 0', 'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "train_df_filtered = train_df_filtered.drop(columns=drop_columns)\n",
    "test_df_filtered = test_df_filtered.drop(columns=drop_columns)\n",
    "\n",
    "# Step 1: Handle missing values and ensure consistent data types\n",
    "def handle_missing_values(df):\n",
    "    df = df.astype(str)\n",
    "    df = df.fillna(\"None\")\n",
    "    return df\n",
    "\n",
    "# Step 2: Preprocess - Encoding categorical variables\n",
    "def preprocess_data(df, target_column, transformer=None):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Reset indices for alignment with FAISS\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    # Handle missing values and ensure consistent data types\n",
    "    X = handle_missing_values(X)\n",
    "\n",
    "    if transformer is None:\n",
    "        transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), X.columns.tolist())\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        transformer.fit(X)\n",
    "    \n",
    "    # Transform features\n",
    "    X_transformed = transformer.transform(X)\n",
    "    return X_transformed.astype(np.float32), y.astype(float), transformer\n",
    "\n",
    "# Step 3: Create FAISS Index with Product Quantization\n",
    "def create_faiss_index(df, target_column, n_clusters=256):\n",
    "    X, y, transformer = preprocess_data(df, target_column)\n",
    "\n",
    "    # Step 3.1: Apply Product Quantization (PQ) for dimensionality reduction\n",
    "    # Number of clusters and number of subquantizers\n",
    "    d = X.shape[1]  # dimensionality of the data\n",
    "    nlist = 100  # Number of coarse centroids (use a large enough value for large datasets)\n",
    "\n",
    "    # Create FAISS index with product quantization (IndexIVFPQ)\n",
    "    quantizer = faiss.IndexFlatL2(d)  # Used for coarse quantization\n",
    "    faiss_index = faiss.IndexIVFPQ(quantizer, d, nlist, n_clusters, 8)  # Use 8 bits per subquantizer\n",
    "\n",
    "    # Train the index (on a subset of the data)\n",
    "    faiss_index.train(X)\n",
    "    \n",
    "    # Add the vectors to the index\n",
    "    faiss_index.add(X)\n",
    "    \n",
    "    return faiss_index, X, y, transformer\n",
    "\n",
    "# Step 4: Predict using FAISS with PQ\n",
    "def predict_faiss_parallel(df, target_column, faiss_index, transformer, y_train, n_neighbors=20, n_jobs=4):\n",
    "    X, y, _ = preprocess_data(df, target_column, transformer)\n",
    "\n",
    "    # Function to process a single observation\n",
    "    def process_vector(test_vector):\n",
    "        D, I = faiss_index.search(np.array([test_vector]), n_neighbors)  # Find nearest neighbors\n",
    "        similar_train_data = y_train.iloc[I[0]]  # Use y_train directly\n",
    "        return similar_train_data.mean()  # Average for prediction\n",
    "    \n",
    "    # Parallelize using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        y_pred = list(executor.map(process_vector, X))\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Step 5: Train the model\n",
    "target_column = 'IS_BANCAS'\n",
    "faiss_index, _, y_train, transformer = create_faiss_index(train_df, target_column)\n",
    "\n",
    "# Save the FAISS index\n",
    "faiss.write_index(faiss_index, 'results/faiss_index.index')\n",
    "\n",
    "# Save the transformer, y_train, and prediction function using dill\n",
    "with open('results/collaborative_search_model_with_pq.pkl', 'wb') as f:\n",
    "    dill.dump({\n",
    "        'transformer': transformer,\n",
    "        'y_train': y_train,\n",
    "        'predict_faiss_parallel': predict_faiss_parallel  # Save the function\n",
    "    }, f)\n",
    "\n",
    "# Step 6: Testing\n",
    "\n",
    "# On training data\n",
    "y_pred_col_train = predict_faiss_parallel(train_df, target_column, faiss_index, transformer, y_train)\n",
    "y_pred_col_train_round = y_pred_col_train.round()\n",
    "\n",
    "# On testing data\n",
    "y_pred_col_test = predict_faiss_parallel(test_df, target_column, faiss_index, transformer, y_train)\n",
    "y_pred_col_test_round = y_pred_col_test.round()\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "# Reporting\n",
    "\n",
    "# On training data\n",
    "print('\\nTESTING ON TRAINING DATA:\\n')\n",
    "\n",
    "accuracy_col_train = accuracy_score(y_train, y_pred_col_train_round)\n",
    "accuracy_col_train = round(accuracy_col_train, 4)\n",
    "roc_auc_score_col_train = roc_auc_score(y_train, y_pred_col_train)\n",
    "gini_col_train = 2 * roc_auc_score_col_train - 1\n",
    "\n",
    "print('Model Accuracy:', str(accuracy_col_train * 100))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_train, y_pred_col_train_round))\n",
    "print(\"ROC AUC Score:\", roc_auc_score_col_train.round(2))\n",
    "print(\"Gini Index:\", gini_col_train.round(2))\n",
    "\n",
    "# On testing data\n",
    "print('\\nTESTING ON TESTING DATA:\\n')\n",
    "\n",
    "accuracy_col_test = accuracy_score(y_test, y_pred_col_test_round)\n",
    "accuracy_col_test = round(accuracy_col_test, 4)\n",
    "roc_auc_score_col_test = roc_auc_score(y_test, y_pred_col_test)\n",
    "gini_col_test = 2 * roc_auc_score_col_test - 1\n",
    "\n",
    "print('Model Accuracy:', str(accuracy_col_test * 100) + '%')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_col_test_round))\n",
    "print(\"ROC AUC Score:\", roc_auc_score_col_test.round(2))\n",
    "print(\"Gini Index:\", gini_col_test.round(2))\n",
    "\n",
    "# ROC Curves\n",
    "\n",
    "# Train data\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_pred_col_train)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "fpr_train = [0] + list(fpr_train)\n",
    "tpr_train = [0] + list(tpr_train)\n",
    "\n",
    "# Test data\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_pred_col_test)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "fpr_test = [0] + list(fpr_test)\n",
    "tpr_test = [0] + list(tpr_test)\n",
    "\n",
    "# Colours\n",
    "background_color = '#181926'\n",
    "text_colour = \"#cad3f5\"\n",
    "axis_colour = \"#b8c0e0\"\n",
    "guess_colour = '#8aadf4'\n",
    "roc_train_colour = \"#f0c6c6\"\n",
    "roc_test_colour = \"#91d7e3\"\n",
    "\n",
    "# Setting up the plot\n",
    "plt.figure(figsize=(10, 8), facecolor=background_color)\n",
    "ax = plt.gca()  # Get the current Axes\n",
    "ax.set_facecolor(background_color)  # Set the background color of the Axes\n",
    "\n",
    "# Customize axis colors\n",
    "ax.tick_params(axis='x', colors=axis_colour)  # Set x-axis tick color\n",
    "ax.tick_params(axis='y', colors=axis_colour)  # Set y-axis tick color\n",
    "ax.spines['bottom'].set_color(axis_colour)  # Set bottom spine color\n",
    "ax.spines['left'].set_color(axis_colour)    # Set left spine color\n",
    "ax.spines['top'].set_color(axis_colour)  # Set bottom spine color\n",
    "ax.spines['right'].set_color(axis_colour)    # Set left spine color\n",
    "\n",
    "# Plotting\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr_train, tpr_train, color=roc_train_colour, label=f'Train Data ROC Curve (AUC = {roc_auc_train:.2f})')\n",
    "plt.plot(fpr_test, tpr_test, color=roc_test_colour, label=f'Test data ROC Curve (AUC = {roc_auc_test:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color=guess_colour, linestyle='--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate', color=text_colour)  # White text for better contrast\n",
    "plt.ylabel('True Positive Rate', color=text_colour)  # White text for better contrast\n",
    "plt.title('Next Best Action Receiver Operating Characteristic (ROC) Curve', color=text_colour)\n",
    "plt.legend(loc='lower right', facecolor=background_color, edgecolor=text_colour, labelcolor=text_colour)\n",
    "plt.grid(alpha=0.1, color=axis_colour)  # Adjust grid line color for visibility\n",
    "\n",
    "# Set the x and y limits to start at 0\n",
    "plt.xlim(0, 1)  # x-axis starts at 0\n",
    "plt.ylim(0, 1)  # y-axis starts at 0\n",
    "\n",
    "plt.savefig('results/NBA_ROC.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab213c-9cb3-4602-9f7a-5ff2d0f88012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import dill\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, auc\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from datasketch import MinHash, MinHashLSH\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "train_df = pd.read_csv('data.csv')\n",
    "test_df = pd.read_parquet('data-val.parquet')\n",
    "\n",
    "# Ensure the datasets have the same columns\n",
    "common_columns = train_df.columns.intersection(test_df.columns)\n",
    "removed_columns = set(train_df.columns).symmetric_difference(test_df.columns)\n",
    "train_df_filtered = train_df[common_columns]\n",
    "test_df_filtered = test_df[common_columns]\n",
    "\n",
    "# Dropping irrelevant columns\n",
    "drop_columns = ['Age_x', 'CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', 'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', \n",
    "                'CIF_MASK', 'IS_TM', 'Unnamed: 0', 'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH']\n",
    "train_df_filtered = train_df_filtered.drop(columns=drop_columns)\n",
    "test_df_filtered = test_df_filtered.drop(columns=drop_columns)\n",
    "\n",
    "# Step 1: Handle missing values and ensure consistent data types\n",
    "def handle_missing_values(df):\n",
    "    df = df.astype(str)\n",
    "    df = df.fillna(\"None\")\n",
    "    return df\n",
    "\n",
    "# Step 2: Preprocess - Encoding categorical variables\n",
    "def preprocess_data(df, target_column, transformer=None):\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Reset indices for alignment with LSH\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    # Handle missing values and ensure consistent data types\n",
    "    X = handle_missing_values(X)\n",
    "\n",
    "    if transformer is None:\n",
    "        transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), X.columns.tolist())\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        transformer.fit(X)\n",
    "    \n",
    "    # Transform features\n",
    "    X_transformed = transformer.transform(X)\n",
    "    return X_transformed.astype(np.float32), y.astype(float), transformer\n",
    "\n",
    "# Step 3: Create LSH Index using MinHash\n",
    "def create_lsh_index(df, target_column, num_hashes=200):\n",
    "    X, y, transformer = preprocess_data(df, target_column)\n",
    "\n",
    "    # Step 3.1: MinHash LSH index\n",
    "    lsh = MinHashLSH(threshold=0.9, num_perm=num_hashes)  # Threshold for similarity\n",
    "    minhashes = {}\n",
    "    \n",
    "    for i, vector in enumerate(X):\n",
    "        minhash = MinHash(num_perm=num_hashes)\n",
    "        # Create MinHash from vector (convert vector to set of hashes)\n",
    "        for val in vector:\n",
    "            minhash.update(str(val).encode('utf8'))\n",
    "        minhashes[i] = minhash\n",
    "        lsh.insert(i, minhash)  # Insert the MinHash into the LSH index\n",
    "    \n",
    "    return lsh, X, y, transformer\n",
    "\n",
    "# Step 4: Predict using LSH\n",
    "def predict_lsh_parallel(df, target_column, lsh, transformer, y_train, n_neighbors=20, n_jobs=4):\n",
    "    X, y, _ = preprocess_data(df, target_column, transformer)\n",
    "\n",
    "    # Function to process a single observation\n",
    "    def process_vector(test_vector):\n",
    "        # Convert vector to MinHash\n",
    "        minhash = MinHash(num_perm=200)\n",
    "        for val in test_vector:\n",
    "            minhash.update(str(val).encode('utf8'))\n",
    "        \n",
    "        # Find nearest neighbors using LSH\n",
    "        result = lsh.query(minhash)  # Retrieve similar hash values\n",
    "        similar_train_data = y_train.iloc[result]  # Use y_train directly\n",
    "        return similar_train_data.mean()  # Average for prediction\n",
    "    \n",
    "    # Parallelize using ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=n_jobs) as executor:\n",
    "        y_pred = list(executor.map(process_vector, X))\n",
    "    \n",
    "    return np.array(y_pred)\n",
    "\n",
    "# Step 5: Train the model\n",
    "target_column = 'IS_BANCAS'\n",
    "lsh, _, y_train, transformer = create_lsh_index(train_df, target_column)\n",
    "\n",
    "# Save the transformer, y_train, and prediction function using dill\n",
    "with open('results/collaborative_search_model_with_lsh.pkl', 'wb') as f:\n",
    "    dill.dump({\n",
    "        'transformer': transformer,\n",
    "        'y_train': y_train,\n",
    "        'predict_lsh_parallel': predict_lsh_parallel  # Save the function\n",
    "    }, f)\n",
    "\n",
    "# Step 6: Testing\n",
    "\n",
    "# On training data\n",
    "y_pred_col_train = predict_lsh_parallel(train_df, target_column, lsh, transformer, y_train)\n",
    "y_pred_col_train_round = y_pred_col_train.round()\n",
    "\n",
    "# On testing data\n",
    "y_pred_col_test = predict_lsh_parallel(test_df, target_column, lsh, transformer, y_train)\n",
    "y_pred_col_test_round = y_pred_col_test.round()\n",
    "y_test = test_df[target_column]\n",
    "\n",
    "# Reporting\n",
    "\n",
    "# On training data\n",
    "print('\\nTESTING ON TRAINING DATA:\\n')\n",
    "\n",
    "accuracy_col_train = accuracy_score(y_train, y_pred_col_train_round)\n",
    "accuracy_col_train = round(accuracy_col_train, 4)\n",
    "roc_auc_score_col_train = roc_auc_score(y_train, y_pred_col_train)\n",
    "gini_col_train = 2 * roc_auc_score_col_train - 1\n",
    "\n",
    "print('Model Accuracy:', str(accuracy_col_train * 100))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_train, y_pred_col_train_round))\n",
    "print(\"ROC AUC Score:\", roc_auc_score_col_train.round(2))\n",
    "print(\"Gini Index:\", gini_col_train.round(2))\n",
    "\n",
    "# On testing data\n",
    "print('\\nTESTING ON TESTING DATA:\\n')\n",
    "\n",
    "accuracy_col_test = accuracy_score(y_test, y_pred_col_test_round)\n",
    "accuracy_col_test = round(accuracy_col_test, 4)\n",
    "roc_auc_score_col_test = roc_auc_score(y_test, y_pred_col_test)\n",
    "gini_col_test = 2 * roc_auc_score_col_test - 1\n",
    "\n",
    "print('Model Accuracy:', str(accuracy_col_test * 100) + '%')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_col_test_round))\n",
    "print(\"ROC AUC Score:\", roc_auc_score_col_test.round(2))\n",
    "print(\"Gini Index:\", gini_col_test.round(2))\n",
    "\n",
    "# ROC Curves\n",
    "\n",
    "# Train data\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_pred_col_train)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "fpr_train = [0] + list(fpr_train)\n",
    "tpr_train = [0] + list(tpr_train)\n",
    "\n",
    "# Test data\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_pred_col_test)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "fpr_test = [0] + list(fpr_test)\n",
    "tpr_test = [0] + list(tpr_test)\n",
    "\n",
    "# Colours\n",
    "background_color = '#181926'\n",
    "text_colour = \"#cad3f5\"\n",
    "axis_colour = \"#b8c0e0\"\n",
    "guess_colour = '#8aadf4'\n",
    "roc_train_colour = \"#f0c6c6\"\n",
    "roc_test_colour = \"#91d7e3\"\n",
    "\n",
    "# Setting up the plot\n",
    "plt.figure(figsize=(10, 8), facecolor=background_color)\n",
    "ax = plt.gca()  # Get the current Axes\n",
    "ax.set_facecolor(background_color)  # Set the background color of the Axes\n",
    "\n",
    "# Customize axis colors\n",
    "ax.tick_params(axis='x', colors=axis_colour)  # Set x-axis tick color\n",
    "ax.tick_params(axis='y', colors=axis_colour)  # Set y-axis tick color\n",
    "ax.spines['bottom'].set_color(axis_colour)  # Set bottom spine color\n",
    "ax.spines['left'].set_color(axis_colour)    # Set left spine color\n",
    "ax.spines['top'].set_color(axis_colour)  # Set bottom spine color\n",
    "ax.spines['right'].set_color(axis_colour)    # Set left spine color\n",
    "\n",
    "# Plotting\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.plot(fpr_train, tpr_train, color=roc_train_colour, label=f'Train Data ROC Curve (AUC = {roc_auc_train:.2f})')\n",
    "plt.plot(fpr_test, tpr_test, color=roc_test_colour, label=f'Test data ROC Curve (AUC = {roc_auc_test:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color=guess_colour, linestyle='--', label='Random Guess')\n",
    "plt.xlabel('False Positive Rate', color=text_colour)  # White text for better contrast\n",
    "plt.ylabel('True Positive Rate', color=text_colour)  # White text for better contrast\n",
    "plt.title('Next Best Action Receiver Operating Characteristic (ROC) Curve', color=text_colour)\n",
    "plt.legend(loc='lower right', facecolor=background_color, edgecolor=text_colour, labelcolor=text_colour)\n",
    "plt.grid(alpha=0.1, color=axis_colour)  # Adjust grid line color for visibility\n",
    "\n",
    "# Set the x and y limits to start at 0\n",
    "plt.xlim(0, 1)  # x-axis starts at 0\n",
    "plt.ylim(0, 1)  # y-axis starts at 0\n",
    "\n",
    "plt.savefig('results/NBA_ROC.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
