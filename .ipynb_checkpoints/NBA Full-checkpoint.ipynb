{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd0d24dd-6b29-45ec-8013-fab8a6cac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from annoy import AnnoyIndex\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, roc_auc_score, roc_curve\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bc572b9-0ef5-4ef6-9b20-5d3ae3fa1266",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data.csv')\n",
    "test_df = pd.read_parquet('data-val.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12196a84-097a-4467-b796-18da0fc411e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed columns: {'SUM_NOT_TRANSFER_3m', 'Unnamed: 0.1', 'SUM_AMT_TRANSFER_3m'}\n"
     ]
    }
   ],
   "source": [
    "## Make sure that the dataset \n",
    "\n",
    "# Find common columns\n",
    "common_columns = train_df.columns.intersection(test_df.columns)\n",
    "\n",
    "# Drop uncommon columns\n",
    "removed_columns = set(train_df.columns).symmetric_difference(test_df.columns)\n",
    "train_df_filtered = train_df[common_columns]\n",
    "test_df_filtered = test_df[common_columns]\n",
    "\n",
    "# Print removed columns\n",
    "print(\"Removed columns:\", removed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8479343-e089-43c2-8c74-95448a1c8382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 57\n",
      "Test data: 57\n"
     ]
    }
   ],
   "source": [
    "# Comparing number of columns\n",
    "print(\"Train data:\", train_df_filtered.shape[1])\n",
    "print(\"Test data:\", test_df_filtered.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2130e87-821b-407f-bc84-8899c21ff311",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping irrelavant columns\n",
    "\n",
    "# Train_data\n",
    "train_df_filtered = train_df_filtered.drop(columns=['Age_x','CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', 'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', 'CIF_MASK', 'IS_TM', 'Unnamed: 0', 'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH'])\n",
    "\n",
    "# Test_data \n",
    "test_df_filtered = test_df_filtered.drop(columns=['Age_x','CIF_CLSCUS', 'COB_DATE', 'DATE_TIME', 'BRN_OPN_CIF', 'MA_PHONG_GIAO_DICH_VCB', 'CIF_MASK', 'IS_TM', 'Unnamed: 0', 'SUM_CBALQ_LH_6m', 'SUM_CBALQ_LH_3m', 'AVG_GR_SUM_CBALQ_LH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "788cde3a-78d1-47a7-9ce4-085404b59395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 45\n",
      "Test data: 45\n",
      "Selected columns:\n",
      " Index(['CBALQ_3m', 'AVG_SL_SP_BOSUNG', 'NO_TREN_CO_6m',\n",
      "       'LOAIHINHCOQUANDANGCONGTAC', 'SUM_CBALQ_LH', 'BHNT_flag',\n",
      "       'MEDIAN_GR_SUM_AMT', 'TINHTRANGSOHUUNHA', 'TINHTRANGHONNHAN', 'Khu_vuc',\n",
      "       'BHNT_after21', 'Sum_PPC', 'MEDIAN_GR_THGCO', 'BHSK_remain',\n",
      "       'IS_BANCAS', 'AVG_GR_CBALQ', 'CBALQ_6m', 'AVG_CBALQ_6m', 'BHNT_remain',\n",
      "       'AVG_GR_THGCO', 'IS_TM.1', 'Age_y', 'THGCO_3m', 'CNT_TGCCKH',\n",
      "       'THGNO_6m', 'IS_TA', 'TONGTHUNHAPHANGTHANG', 'Snapshot', 'BHSK_flag',\n",
      "       'THGCO_6m', 'MEDIAN_GR_CBALQ', 'AVG_CBALQ_TGCCKH', 'THGNO_3m',\n",
      "       'TINHCHATCONGVIECHIENTAI', 'AVG_AMT_3M', 'NO_TREN_CO_3m',\n",
      "       'AVG_CBALQ_3m', 'Prio_flag', 'SONGUOIPHUTHUOC', 'THOIGIANLAMVIECLVHT',\n",
      "       'BHSK_after21', 'Payroll_Flag', 'AVG_GR_THGNO', 'CUS_GEN',\n",
      "       'MEDIAN_GR_THGNO'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Comparing number of columns\n",
    "print(\"Train data:\", train_df_filtered.shape[1])\n",
    "print(\"Test data:\", test_df_filtered.shape[1])\n",
    "print('Selected columns:\\n', test_df_filtered.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "428f5b37-85aa-4b96-b2da-4a66e1269e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n",
      "/home/zeus/.local/share/python/lib/python3.12/site-packages/numpy/lib/function_base.py:4655: RuntimeWarning: invalid value encountered in subtract\n",
      "  diff_b_a = subtract(b, a)\n"
     ]
    }
   ],
   "source": [
    "## Labelling\n",
    "def labelling (df, col, num_bins):\n",
    "    df[col] = pd.qcut(df[col], q=num_bins, labels=False, duplicates='drop')\n",
    "    return df\n",
    "for col in ['AVG_AMT_3M', 'AVG_CBALQ_3m', 'AVG_CBALQ_6m', 'AVG_CBALQ_TGCCKH',\n",
    "       'AVG_GR_CBALQ', 'AVG_GR_THGCO', 'AVG_GR_THGNO', 'AVG_SL_SP_BOSUNG',\n",
    "        'CBALQ_3m', 'CBALQ_6m', 'CNT_TGCCKH', 'MEDIAN_GR_CBALQ',\n",
    "       'MEDIAN_GR_SUM_AMT', 'MEDIAN_GR_THGCO', 'MEDIAN_GR_THGNO',\n",
    "       'NO_TREN_CO_3m', 'NO_TREN_CO_6m', 'SUM_CBALQ_LH', 'Snapshot', 'Sum_PPC',\n",
    "       'THGCO_3m', 'THGCO_6m', 'THGNO_3m', 'THGNO_6m', 'TONGTHUNHAPHANGTHANG']:\n",
    "    train_df = labelling(train_df_filtered, col, 10)\n",
    "    test_df = labelling(test_df_filtered, col, 10)\n",
    "\n",
    "age_bin_edges = [0, 20, 25, 30, 35, 40, 45, 50, 55, 60, float('inf')]\n",
    "labels = ['Duoi 20', '20 toi 24', '25 toi 29', '30 toi 34', '35 toi 39', '40 toi 44', '45 toi 49', '50 toi 54', '55 toi 59', 'Tren 60']\n",
    "\n",
    "train_df['Age_group'] = pd.cut(train_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)\n",
    "test_df['Age_group'] = pd.cut(test_df['Age_y'], bins=age_bin_edges, labels=labels, right=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9844ff1b-3dba-4b0e-b1f1-8120e253101a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collaborative search\n",
    "\n",
    "# Step 1: Handle missing values and ensure consistent data types\n",
    "def handle_missing_values(df):\n",
    "    df = df.astype(str)\n",
    "    df = df.fillna(\"None\")\n",
    "    return df\n",
    "\n",
    "# Step 2: Preprocess - Encoding categorical variables\n",
    "def preprocess_data(df, target_column, transformer=None):\n",
    "    # Separate features (X) and target (y)\n",
    "    X = df.drop(columns=[target_column])\n",
    "    y = df[target_column]\n",
    "    \n",
    "    # Reset indices for alignment with Annoy\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    # Handle missing values and ensure consistent data types\n",
    "    X = handle_missing_values(X)\n",
    "\n",
    "    if transformer is None:\n",
    "        transformer = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), X.columns.tolist())\n",
    "            ],\n",
    "            remainder='passthrough'\n",
    "        )\n",
    "        transformer.fit(X)\n",
    "    \n",
    "    # Transform features\n",
    "    X_transformed = transformer.transform(X)\n",
    "    return X_transformed.astype(np.float32), y.astype(float), transformer\n",
    "\n",
    "# Step 3: Create Annoy Index\n",
    "def create_annoy_index(df, target_column, n_neighbors=20):\n",
    "    # Preprocess the data and separate features and target\n",
    "    X, y, transformer = preprocess_data(df, target_column)\n",
    "    \n",
    "    # Initialize Annoy index\n",
    "    annoy_index = AnnoyIndex(X.shape[1], 'angular')\n",
    "    \n",
    "    # Add items to the Annoy index\n",
    "    for i, vector in enumerate(X):\n",
    "        annoy_index.add_item(i, vector)\n",
    "    \n",
    "    # Build the index\n",
    "    annoy_index.build(100)\n",
    "    \n",
    "    return annoy_index, X, y, transformer  # Return y for later use\n",
    "    \n",
    "def predict_nba(df, target_column, annoy_index, transformer, y_train):\n",
    "    # Preprocess the data and separate features\n",
    "    X, y, _ = preprocess_data(df, target_column, transformer)\n",
    "    \n",
    "    # Prepare an array to hold the predictions\n",
    "    y_pred = []\n",
    "    \n",
    "    # For each test observation, find the 20 nearest neighbors in the train data\n",
    "    for test_vector in X:\n",
    "        nearest_neighbors = annoy_index.get_nns_by_vector(test_vector, 20)  # Get indices of 20 nearest neighbors\n",
    "        similar_train_data = y_train.iloc[nearest_neighbors]  # Use y_train directly\n",
    "        y_pred_value = similar_train_data.mean()  # Average for prediction\n",
    "        y_pred.append(y_pred_value)\n",
    "    \n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1366ad3f-432e-4bb8-9ef4-6f084ecbcbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "target_column = 'IS_BANCAS'\n",
    "annoy_index, _, y_train, transformer = create_annoy_index(train_df, target_column)\n",
    "\n",
    "# Save the Annoy index to a file\n",
    "annoy_index.save('results/annoy_index.ann')\n",
    "\n",
    "# Save the transformer and y_train using pickle\n",
    "with open('results/collaborative_search_model.pkl', 'wb') as f:\n",
    "    pickle.dump((transformer, y_train), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "516c87eb-6b9f-45a0-99a2-6abb5d437535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from annoy import AnnoyIndex\n",
    "# import pickle\n",
    "\n",
    "# # Load the transformer and y_train\n",
    "# with open('collaborative_search_model.pkl', 'rb') as f:\n",
    "#     transformer, y_train = pickle.load(f)\n",
    "\n",
    "# # Load the Annoy index from its file\n",
    "# annoy_index = AnnoyIndex(X.shape[1], 'angular')  # Replace `X.shape[1]` with the correct feature dimension\n",
    "# annoy_index.load('annoy_index.ann')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e18114a1-e7fe-4a9a-8895-4794979aa827",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "## On training data\n",
    "\n",
    "### Collaborative search\n",
    "y_pred_col_train = predict_nba(train_df, target_column, annoy_index, transformer, y_train)\n",
    "y_pred_col_train_round = y_pred_col_train.round()\n",
    "\n",
    "\n",
    "\n",
    "## On testing data\n",
    "\n",
    "y_pred_col_test = predict_nba(test_df, target_column, annoy_index, transformer, y_train)\n",
    "y_pred_col_test_round = y_pred_col_test.round()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1829645e-9507-41c8-8955-0344ff3e6711",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df8530e7-7330-41c3-97c2-8c2ad397a5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ON TRAINING DATA:\n",
      "\n",
      "Model Accuracy: 95.85000000000001\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.99      0.98   1036620\n",
      "         1.0       0.63      0.31      0.41     51831\n",
      "\n",
      "    accuracy                           0.96   1088451\n",
      "   macro avg       0.80      0.65      0.70   1088451\n",
      "weighted avg       0.95      0.96      0.95   1088451\n",
      "\n",
      "TESTING ON TESTING DATA:\n",
      "\n",
      "Model Accuracy: 95.00999999999999%\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.99      0.97    130200\n",
      "         1.0       0.43      0.15      0.23      6510\n",
      "\n",
      "    accuracy                           0.95    136710\n",
      "   macro avg       0.70      0.57      0.60    136710\n",
      "weighted avg       0.93      0.95      0.94    136710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reporting\n",
    "\n",
    "## On training data\n",
    "print('TESTING ON TRAINING DATA:\\n')\n",
    "\n",
    "\n",
    "\n",
    "accuracy_col_train = accuracy_score(y_train, y_pred_col_train_round)\n",
    "accuracy_col_train = round(accuracy_col_train, 4)\n",
    "roc_auc_score_col_train = roc_auc_score(y_train, y_pred_col_train)\n",
    "gini_col_train = 2 * roc_auc_score_col_train -1\n",
    "\n",
    "print('Model Accuracy:', str(accuracy_col_train * 100))\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_train, y_pred_col_train_round))\n",
    "\n",
    "\n",
    "## On testing data\n",
    "print('TESTING ON TESTING DATA:\\n')\n",
    "\n",
    "\n",
    "\n",
    "accuracy_col_test = accuracy_score(y_test, y_pred_col_test_round)\n",
    "accuracy_col_test = round(accuracy_col_test, 4)\n",
    "roc_auc_score_col_test = roc_auc_score(y_test, y_pred_col_test)\n",
    "gini_col_test = 2 * roc_auc_score_col_test -1\n",
    "\n",
    "print('Model Accuracy:', str(accuracy_col_test * 100) + '%')\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred_col_test_round))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61f597d2-8684-4b01-9c4f-49eedb383f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curves\n",
    "\n",
    "## Train data\n",
    "fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_pred_col_train)\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Insert root point (0,0) into fpr and tpr\n",
    "fpr_train = [0] + list(fpr_train)\n",
    "tpr_train = [0] + list(tpr_train)\n",
    "\n",
    "## Test data\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_pred_col_test)\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Insert root point (0,0) into fpr and tpr\n",
    "fpr_test = [0] + list(fpr_test)\n",
    "tpr_test = [0] + list(tpr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f28d49-a172-4951-b9c7-afb466e8f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colours\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
